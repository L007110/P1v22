import torch
import torch.optim as optim
import os
import shutil
import numpy as np
import time
import gc
import sys
import math
import copy

# å¼•å…¥é¡¹ç›®æ¨¡å—
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
import Parameters
import Main
import GNNModel
from logger import global_logger
from Topology import formulate_global_list_dqn


# =======================================================================
# ğŸ”§ 1. ç¼“å†²åŒºæŒä¹…åŒ–è¡¥ä¸ (Buffer Persistence Patch)
# =======================================================================
# è¿™æ˜¯ä¸€ä¸ª"é­”æ³•"ç±»ï¼Œç”¨äºæ‹¦æˆª Main.py ä¸­çš„ GNNReplayBuffer
# ä½¿å¾—ç»éªŒæ± å¯ä»¥åœ¨ä¸åŒçš„ Main.rl() è°ƒç”¨ä¹‹é—´ä¼ é€’ï¼Œé˜²æ­¢ç¾éš¾æ€§é—å¿˜
class PersistentBufferWrapper:
    _instance_store = []  # é™æ€å˜é‡ï¼Œå­˜å‚¨ä¸Šä¸€è½®çš„ buffer æ•°æ®

    def __new__(cls, *args, **kwargs):
        # åˆ›å»ºçœŸæ­£çš„ GNNReplayBuffer å®ä¾‹ (å¼•ç”¨ Main ä¸­çš„åŸå§‹ç±»)
        real_buffer = Main.GNNReplayBuffer(*args, **kwargs)

        # å¦‚æœæœ‰å­˜è´§ï¼Œæ³¨å…¥æ—§æ•°æ®
        if cls._instance_store:
            print(f"   ğŸ”„ [Buffer Patch] æ­£åœ¨æ³¨å…¥ä¸Šä¸€å…³çš„ç»éªŒæ•°æ®...")
            old_buffer_data = cls._instance_store[0]
            # å°†æ—§æ•°æ®æ·±æ‹·è´åˆ°æ–° buffer (é˜²æ­¢å¼•ç”¨é—®é¢˜)
            real_buffer.buffer = copy.deepcopy(old_buffer_data)
            print(f"   âœ… æˆåŠŸæ¢å¤ {len(real_buffer)} æ¡ç»éªŒ (æ··åˆè®­ç»ƒå¼€å¯)")

        # æ¸…ç©ºå­˜å‚¨ï¼Œå‡†å¤‡æ¥æ”¶æ–°çš„ï¼ˆè™½ç„¶è¿™é‡Œæˆ‘ä»¬å…¶å®åªéœ€è¦åœ¨ rl ç»“æŸæ—¶ä¿å­˜ï¼‰
        # ä½†ä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬åœ¨ rl ç»“æŸåæ‰‹åŠ¨å»æŠ“å– global_gnn_buffer
        return real_buffer

    @classmethod
    def save_buffer(cls, buffer_instance):
        """åœ¨ rl ç»“æŸåæ‰‹åŠ¨è°ƒç”¨æ­¤æ–¹æ³•ä¿å­˜æ•°æ®"""
        if buffer_instance is not None and len(buffer_instance) > 0:
            cls._instance_store = [buffer_instance.buffer]
            print(f"   ğŸ’¾ [Buffer Patch] å·²ä¿å­˜æœ¬å…³å¡ {len(buffer_instance)} æ¡ç»éªŒç”¨äºä¸‹ä¸€å…³")


# âš¡ åº”ç”¨è¡¥ä¸ï¼šæ›¿æ¢ Main æ¨¡å—ä¸­çš„ç±»å®šä¹‰
# æ³¨æ„ï¼šè¿™ä¸ä¼šä¿®æ”¹æ–‡ä»¶ï¼Œåªä¼šä¿®æ”¹è¿è¡Œæ—¶çš„ç±»å¼•ç”¨
OriginalReplayBufferClass = Main.GNNReplayBuffer  # å¤‡ä»½åŸç±»ï¼ˆè™½ç„¶è¿™é‡Œç›´æ¥æ›¿æ¢äº†ï¼‰


# è¿™é‡Œçš„é€»è¾‘ç¨å¾®è°ƒæ•´ï¼šå› ä¸º Main.rl å†…éƒ¨æ˜¯ `global_gnn_buffer = GNNReplayBuffer(...)`
# æˆ‘ä»¬éœ€è¦æ›¿æ¢ Main.GNNReplayBuffer è¿™ä¸ªåå­—æŒ‡å‘æˆ‘ä»¬çš„ Wrapper é€»è¾‘
# ä½†ç”±äº __new__ æ¯”è¾ƒå¤æ‚ï¼Œæˆ‘ä»¬é‡‡ç”¨æ›´ç®€å•çš„"ç±»æ¬ºéª—"
class PatchedGNNReplayBuffer(Main.GNNReplayBuffer):
    def __init__(self, capacity):
        super().__init__(capacity)
        # å°è¯•æ¢å¤æ•°æ®
        if PersistentBufferWrapper._instance_store:
            print(f"   ğŸ”„ [Memory] ç»§æ‰¿ä¸Šä¸€å…³ç»éªŒæ± : {len(PersistentBufferWrapper._instance_store[0])} æ¡æ ·æœ¬")
            self.buffer = copy.deepcopy(PersistentBufferWrapper._instance_store[0])


Main.GNNReplayBuffer = PatchedGNNReplayBuffer

# =======================================================================
# 2. è¯¾ç¨‹é…ç½® (Curriculum Config)
# =======================================================================

LEVEL_CONFIGS = {
    # N : (LR, TotalEpochs, StartEpsilon)
    # N=60: åŸºç¡€å¤¯å®ï¼Œé«˜æ¢ç´¢
    60: (0.0004, 400, 0.5),
    # N=80: è¿›é˜¶ï¼Œé™ä½æ¢ç´¢ï¼Œé˜²æ­¢ç ´åå·²æœ‰ç­–ç•¥
    80: (0.0004, 300, 0.2),
    # N=100: æ‹¥å µï¼Œä½æ¢ç´¢
    100: (0.0003, 300, 0.15),
    # N=120: ä¸¥é‡æ‹¥å µ
    120: (0.0003, 300, 0.1),
    # N=140: æé™
    140: (0.0002, 300, 0.1)
}

CURRICULUM_LEVELS = sorted(LEVEL_CONFIGS.keys())

PASS_THRESHOLDS = {
    60: 0.85, 80: 0.88, 100: 0.90, 120: 0.85, 140: 0.80
}

FINAL_EPSILON = 0.01
FINAL_MODEL_NAME = "model_Universal_LargeMap_v2.pt"


# =======================================================================
# 3. è¾…åŠ©å‡½æ•°
# =======================================================================

def calculate_decay(start_eps, end_eps, total_epochs):
    # å‰ 80% çš„ Epoch è¡°å‡å®Œï¼Œå 20% çº¯åˆ©ç”¨
    target_step = int(total_epochs * 0.80)
    if target_step <= 0: return 0.9
    return math.pow(end_eps / start_eps, 1.0 / target_step)


def run_adaptive_curriculum_v2():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    print(f"\n{'=' * 70}")
    print(f"ğŸš€ å¯åŠ¨å¢å¼ºç‰ˆè¯¾ç¨‹å­¦ä¹  (Smart Curriculum V2)")
    print(f"âœ¨ ç‰¹æ€§: ç»éªŒå›æ”¾æ± æŒä¹…åŒ– + æ™ºèƒ½ Epsilon è¡°å‡")
    print(f"ğŸ“ è®¾å¤‡: {device}")
    print(f"ğŸ“ˆ è·¯çº¿: {CURRICULUM_LEVELS}")
    print(f"{'=' * 70}\n")

    # å¼ºåˆ¶è¦†ç›–å‚æ•°
    Parameters.USE_GNN_ENHANCEMENT = True
    Parameters.GNN_ARCH = "HYBRID"
    Parameters.SCENE_SCALE_X = 1200
    Parameters.SCENE_SCALE_Y = 1200

    last_passed_model_path = None
    current_level_idx = 0

    while current_level_idx < len(CURRICULUM_LEVELS):
        n_vehicles = CURRICULUM_LEVELS[current_level_idx]
        current_lr, total_epochs, start_epsilon = LEVEL_CONFIGS[n_vehicles]
        target_score = PASS_THRESHOLDS.get(n_vehicles, 0.80)

        # åŠ¨æ€è®¡ç®— Decay
        decay_rate = calculate_decay(start_epsilon, FINAL_EPSILON, total_epochs)

        print(f"\n" + "=" * 60)
        print(f"ğŸ”¥ [LEVEL {current_level_idx + 1}] N={n_vehicles} | LR={current_lr} | Epochs={total_epochs}")
        print(f"ğŸ² Epsilon: {start_epsilon} -> {FINAL_EPSILON} (Decay: {decay_rate:.5f})")
        print("=" * 60)

        # --- 1. ç¯å¢ƒå‡†å¤‡ ---
        gc.collect()
        torch.cuda.empty_cache()

        Parameters.TRAINING_VEHICLE_TARGET = n_vehicles
        Parameters.NUM_VEHICLES = n_vehicles
        Parameters.RL_N_EPOCHS = total_epochs
        Parameters.ABLATION_SUFFIX = f"_Lvl{current_level_idx}_N{n_vehicles}"

        global_logger._init_metrics_storage()
        formulate_global_list_dqn(Parameters.global_dqn_list, device)

        # è®¾ç½® Epsilon (æ™ºèƒ½è®¾å®š)
        for dqn in Parameters.global_dqn_list:
            dqn.epsilon = start_epsilon

        # --- 2. æ¨¡å‹åŠ è½½ä¸åŒæ­¥ ---
        GNNModel.global_gnn_model = GNNModel.EnhancedHeteroGNN(
            node_feature_dim=12, hidden_dim=64
        ).to(device)
        GNNModel.global_target_gnn_model = GNNModel.EnhancedHeteroGNN(
            node_feature_dim=12, hidden_dim=64
        ).to(device)

        if last_passed_model_path and os.path.exists(last_passed_model_path):
            print(f"   ğŸ“¥ ç»§æ‰¿æƒé‡: {last_passed_model_path}")
            checkpoint = torch.load(last_passed_model_path, map_location=device)
            GNNModel.global_gnn_model.load_state_dict(checkpoint)
            # å…³é”®ï¼šä¸¥æ ¼åŒæ­¥ Target
            GNNModel.global_target_gnn_model.load_state_dict(checkpoint)
        else:
            print("   ğŸŒ± [Cold Start] åˆå§‹åŒ–ç½‘ç»œ")
            GNNModel.update_target_gnn()

        # ä¼˜åŒ–å™¨
        gnn_optimizer = optim.Adam(GNNModel.global_gnn_model.parameters(), lr=current_lr)

        # --- 3. è®­ç»ƒ ---
        try:
            # Main.rl ä¼šè§¦å‘ PatchedGNNReplayBufferï¼Œè‡ªåŠ¨åŠ è½½æ—§æ•°æ®
            Main.rl(gnn_optimizer=gnn_optimizer, device=device)

            # è®­ç»ƒç»“æŸï¼Œä¿å­˜å½“å‰ Buffer ä¾›ä¸‹ä¸€å…³ä½¿ç”¨
            # Main.global_gnn_buffer æ˜¯ Main.py æ¨¡å—çº§çš„å¼•ç”¨å—ï¼Ÿä¸æ˜¯ï¼Œå®ƒæ˜¯ rl å†…éƒ¨çš„å±€éƒ¨å˜é‡
            # ç³Ÿç³•ï¼Œæˆ‘ä»¬æ— æ³•ä»å¤–éƒ¨è®¿é—® rl å†…éƒ¨çš„ bufferã€‚
            # ä¿®æ­£ç­–ç•¥ï¼šæˆ‘ä»¬åœ¨ PatchedGNNReplayBuffer çš„ææ„æˆ–è€…é€šè¿‡å…¨å±€å¼•ç”¨æ¥æŠ“å–
            # ç”±äº Python å¼•ç”¨æœºåˆ¶ï¼Œåªè¦ Main.rl è·‘å®Œï¼Œlocal å˜é‡å°±æ²¡äº†ã€‚
            # ä½†æˆ‘ä»¬åœ¨ Main.py é‡Œæ— æ³•ä¿®æ”¹ returnã€‚
            # è¡¥æ•‘ï¼šæˆ‘ä»¬åœ¨ Patch ç±»é‡Œåšä¸€ä¸ªé’©å­ï¼Œæ¯æ¬¡ add çš„æ—¶å€™æ›´æ–°ä¸€ä¸‹é™æ€å­˜å‚¨ï¼Ÿå¤ªæ…¢ã€‚
            # è¡¥æ•‘ V2ï¼šMain.py çš„ rl å‡½æ•°æ²¡æœ‰è¿”å› bufferã€‚
            # ç»ˆæè¡¥ä¸ï¼šMain.py è¿è¡Œä¸­ global_gnn_buffer æ˜¯å±€éƒ¨å˜é‡ï¼Œä½†åœ¨è¿è¡Œç»“æŸå‰æ— æ³•è·å–ã€‚
            # ç­‰ç­‰ï¼ŒMain.py æœ‰ `import GNNReplayBuffer`ã€‚
            # æˆ‘ä»¬å…¶å®åœ¨ `rl` å¾ªç¯é‡Œï¼Œ`global_gnn_buffer` åªæ˜¯è¢«ç”¨æ¥ sample å’Œ addã€‚

            # è¿™é‡Œçš„ Hackï¼š
            # æˆ‘ä»¬åœ¨ PatchedGNNReplayBuffer ä¸­ç»´æŒä¸€ä¸ªç±»çº§åˆ«çš„å¼•ç”¨æŒ‡å‘"å½“å‰æ´»è·ƒçš„buffer"
            # è¿™æ ·æˆ‘ä»¬åœ¨å¤–éƒ¨å°±å¯ä»¥è®¿é—®äº†
            if hasattr(PatchedGNNReplayBuffer, 'current_instance'):
                active_buf = PatchedGNNReplayBuffer.current_instance
                PersistentBufferWrapper.save_buffer(active_buf)

            # --- ä¿å­˜æ¨¡å‹ ---
            save_name = f"checkpoint_passed_N{n_vehicles}.pt"
            torch.save(GNNModel.global_gnn_model.state_dict(), save_name)
            last_passed_model_path = save_name
            current_level_idx += 1
            print(f"   âœ… N={n_vehicles} å®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜ã€‚")

        except Exception as e:
            print(f"   âŒ è®­ç»ƒä¸­æ–­: {e}")
            import traceback
            traceback.print_exc()
            return

    print("\n" + "=" * 70)
    print("ğŸ† é€šç”¨æ¨¡å‹è®­ç»ƒå…¨éƒ¨å®Œæˆï¼")
    if last_passed_model_path:
        shutil.copy(last_passed_model_path, FINAL_MODEL_NAME)
        print(f"ğŸ’¾ æœ€ç»ˆé€šç”¨æ¨¡å‹: {FINAL_MODEL_NAME}")
    print("=" * 70)


# æ›´æ–°ä¸€ä¸‹ Patch ç±»ï¼Œå¢åŠ  current_instance é’©å­
class PatchedGNNReplayBuffer_V2(Main.GNNReplayBuffer):
    current_instance = None  # é™æ€å¼•ç”¨

    def __init__(self, capacity):
        super().__init__(capacity)
        PatchedGNNReplayBuffer_V2.current_instance = self  # æ•è·å¼•ç”¨

        # å°è¯•æ¢å¤æ•°æ®
        if PersistentBufferWrapper._instance_store:
            print(f"   ğŸ”„ [Buffer Patch] æ³¨å…¥ä¸Šä¸€å…³ç»éªŒ: {len(PersistentBufferWrapper._instance_store[0])} æ¡")
            self.buffer = copy.deepcopy(PersistentBufferWrapper._instance_store[0])


# é‡æ–°åº”ç”¨ V2 è¡¥ä¸
Main.GNNReplayBuffer = PatchedGNNReplayBuffer_V2

if __name__ == "__main__":
    run_adaptive_curriculum_v2()